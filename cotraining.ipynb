{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UN7UavpVfqVc"
   },
   "source": [
    "# co-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "abGNtimgfqVh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xWEikDnHfqVl"
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_predictions(pred, k):\n",
    "    prob, label = torch.max(pred, 1)\n",
    "    idx = torch.argsort(prob, descending=True)[:k]\n",
    "    return prob[idx], label[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO extract some of the logic into another function (so messy...)\n",
    "def remove_collisions(lbl_model0, idx_model0, lbl_model1, idx_model1):\n",
    "    # convert tensors to np arrays, as mixing use of tensors\n",
    "    # and arrays together can cause some strange behaviors\n",
    "    # (they will still both point to the same place in memory)\n",
    "    lbl_model0_np = lbl_model0.cpu().detach().numpy()\n",
    "    lbl_model1_np = lbl_model1.cpu().detach().numpy()\n",
    "    idx_model0_np = idx_model0.cpu().detach().numpy()\n",
    "    idx_model1_np = idx_model1.cpu().detach().numpy()\n",
    "    \n",
    "    # find which instances have been labeled with \n",
    "    # the most confidence by both model0 and model1\n",
    "    inter, idx_inter0, idx_inter1 = np.intersect1d(\n",
    "                                        idx_model0_np,\n",
    "                                        idx_model1_np,\n",
    "                                        return_indices=True)\n",
    "\n",
    "    print('Intersection: {} \\nidx_inter0: {} \\nidx_inter1: {}'\n",
    "          .format(inter, idx_inter0, idx_inter1))\n",
    "\n",
    "    # which instances have a conflicting prediction from both models?\n",
    "    mask_coll = lbl_model0_np[idx_inter0] != lbl_model1_np[idx_inter1]\n",
    "    idx_colls = inter[mask_coll]\n",
    "    lbl_colls = []\n",
    "\n",
    "    if (len(idx_colls) > 0):\n",
    "        print(\"Idx cols\", idx_colls)\n",
    "        idx_coll0 = idx_inter0[mask_coll]\n",
    "        idx_coll1 = idx_inter1[mask_coll]\n",
    "        \n",
    "        mask0 = np.ones(len(idx_model0), dtype=bool)\n",
    "        mask1 = np.ones(len(idx_model1), dtype=bool)\n",
    "        mask0[idx_coll0] = False\n",
    "        mask1[idx_coll1] = False\n",
    "        \n",
    "        lbl_coll0 = lbl_model0_np[mask0]\n",
    "        lbl_coll1 = lbl_model1_np[mask1]\n",
    "        lbl_colls = list(zip(lbl_coll0, lbl_coll1))\n",
    "\n",
    "        mask = mask0 & mask1\n",
    "        lbl_model0_np = lbl_model0_np[mask]\n",
    "        idx_model0_np = idx_model0_np[mask]\n",
    "\n",
    "        lbl_model1_np = lbl_model1_np[mask]\n",
    "        idx_model1_np = idx_model1_np[mask]\n",
    "\n",
    "    return lbl_model0_np, idx_model0_np, lbl_model1_np, idx_model1_np, lbl_colls, idx_colls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b1ee68f2bb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# verifying that conflicting predictions are removed accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0918, 0.4794, 0.8106],\n",
       "        [0.0151, 0.0153, 0.6036],\n",
       "        [0.2318, 0.8633, 0.9859],\n",
       "        [0.1975, 0.0830, 0.4253]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out0 = torch.rand((4, 3))\n",
    "out0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9859, 0.8106, 0.6036]) tensor([2, 2, 2]) tensor([2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "probs0, labs0, idxs0 = get_topk_predictions(out0, 3)\n",
    "print(probs0, labs0, idxs0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection: [] \n",
      "idx_inter0: [] \n",
      "idx_inter1: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 2]),\n",
       " array([2, 0, 1]),\n",
       " array([1, 0, 1]),\n",
       " array([5, 3, 4]),\n",
       " [],\n",
       " array([], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs1 = torch.tensor([1, 0, 1])\n",
    "idxs1 = torch.tensor([5, 3, 4])\n",
    "remove_collisions(labs0, idxs0, labs1, idxs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection: [0 1 2] \n",
      "idx_inter0: [1 2 0] \n",
      "idx_inter1: [2 0 1]\n",
      "Idx cols [0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " [(2, 2)],\n",
       " array([0, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs2 = torch.tensor([1, 2, 0])\n",
    "idxs2 = torch.tensor([1, 2, 0])\n",
    "remove_collisions(labs0, idxs0, labs2, idxs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection: [0 1 2] \n",
      "idx_inter0: [1 2 0] \n",
      "idx_inter1: [1 2 0]\n",
      "Idx cols [2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2, 2]),\n",
       " array([0, 1]),\n",
       " array([2, 2]),\n",
       " array([0, 1]),\n",
       " [(2, 2), (2, 2)],\n",
       " array([2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs3 = torch.tensor([1, 2, 2])\n",
    "idxs3 = torch.tensor([2, 0, 1])\n",
    "remove_collisions(labs0, idxs0, labs3, idxs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection: [0 1 2] \n",
      "idx_inter0: [1 2 0] \n",
      "idx_inter1: [1 2 0]\n",
      "Idx cols [0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " [],\n",
       " array([0, 1, 2]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs4 = torch.tensor([0, 0, 0])\n",
    "idxs4 = torch.tensor([2, 0, 1])\n",
    "remove_collisions(labs0, idxs0, labs4, idxs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# verifying that function to split the dataset works as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits the datasets of the two views so that\n",
    "# the instances inside are still aligned by index\n",
    "def train_test_split_samples(samples0, samples1, test_size, random_state=None):\n",
    "    if random_state is not None:\n",
    "        random.seed(random_state)\n",
    "\n",
    "    assert test_size > 0 and test_size < 1, \\\n",
    "        'test_size should be a float between (0, 1)'\n",
    "\n",
    "    assert len(samples0) == len(samples1), \\\n",
    "        'number of samples in samples0, samples1 are not equal'\n",
    "    \n",
    "    idx_samples = list(range(len(samples0)))\n",
    "    idx_test = random.sample(idx_samples, floor(test_size * len(samples0)))\n",
    "    idx_train = list(set(idx_samples) - set(idx_test))\n",
    "\n",
    "    # convert to np array for convenient array indexing\n",
    "    samples0_np = np.stack([np.array(a) for a in samples0])\n",
    "    samples1_np = np.stack([np.array(a) for a in samples1])\n",
    "    \n",
    "    samples_train0 = [(str(a[0]), int(a[1])) for a in list(samples0_np[idx_train])]\n",
    "    samples_test0 = [(str(a[0]), int(a[1])) for a in list(samples0_np[idx_test])]\n",
    "    samples_train1 = [(str(a[0]), int(a[1])) for a in list(samples1_np[idx_train])]\n",
    "    samples_test1 = [(str(a[0]), int(a[1])) for a in list(samples1_np[idx_test])]\n",
    "\n",
    "    return samples_train0, samples_test0, samples_train1, samples_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cotraining_samples_lists_fixed.pkl', 'rb') as fp:\n",
    "    dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 4303\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples: {len(dict['labeled'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into labeled/unlabeled\n",
    "samples_train0, samples_unlbl0, samples_train1, samples_unlbl1 = \\\n",
    "    train_test_split_samples(dict['labeled'], dict['inferred'],\n",
    "                             test_size=0.75, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples (train0): 1076\n",
      "Number of samples (unlabeled0): 3227\n",
      "Number of samples (train1): 1076\n",
      "Number of samples (unlabeled1): 3227\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples (train0): {len(samples_train0)}\")\n",
    "print(f\"Number of samples (unlabeled0): {len(samples_unlbl0)}\")\n",
    "\n",
    "print(f\"Number of samples (train1): {len(samples_train1)}\")\n",
    "print(f\"Number of samples (unlabeled1): {len(samples_unlbl1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data so we get 70/10/20 train/val/test\n",
    "samples_train0, samples_test0, samples_train1, samples_test1 = \\\n",
    "        train_test_split_samples(samples_train0, samples_train1,\n",
    "                                 test_size=0.2, random_state=13)\n",
    "\n",
    "samples_train0, samples_val0, samples_train1, samples_val1 = \\\n",
    "        train_test_split_samples(samples_train0, samples_train1,\n",
    "                                 test_size=0.125, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples (train0): 754\n",
      "Number of samples (validation0): 107\n",
      "Number of samples (test0): 215\n",
      "Number of samples (unlabeled0): 3227\n",
      "Number of samples (train1): 754\n",
      "Number of samples (validation1): 107\n",
      "Number of samples (test1): 215\n",
      "Number of samples (unlabeled1): 3227\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples (train0): {len(samples_train0)}\")\n",
    "print(f\"Number of samples (validation0): {len(samples_val0)}\")\n",
    "print(f\"Number of samples (test0): {len(samples_test0)}\")\n",
    "print(f\"Number of samples (unlabeled0): {len(samples_unlbl0)}\")\n",
    "\n",
    "print(f\"Number of samples (train1): {len(samples_train1)}\")\n",
    "print(f\"Number of samples (validation1): {len(samples_val1)}\")\n",
    "print(f\"Number of samples (test1): {len(samples_test1)}\")\n",
    "print(f\"Number of samples (unlabeled1): {len(samples_unlbl1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# making some dummy imagefolder objects to pass in the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imagefolder(data, samples, path, transform=None, new_path=None):\n",
    "    imgfolder = datasets.ImageFolder(path, transform=transform)\n",
    "    imgfolder.class_to_idx = data['class_map']\n",
    "    imgfolder.classes = list(data['class_map'].keys())\n",
    "    imgfolder.samples = samples\n",
    "\n",
    "    if new_path is not None:\n",
    "        imgfolder.root = new_path\n",
    "\n",
    "    return imgfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageFolder objects for first view\n",
    "dummy_path = '/ourdisk/hpc/ai2es/jroth/data/labeled'\n",
    "data_train0 = create_imagefolder(dict, samples_train0, dummy_path, trans)\n",
    "data_unlbl0 = create_imagefolder(dict, samples_unlbl0, dummy_path, trans)\n",
    "data_val0 = create_imagefolder(dict, samples_val0, dummy_path, trans)\n",
    "data_test0 = create_imagefolder(dict, samples_test0, dummy_path, trans)\n",
    "\n",
    "# Create ImageFolder objects for second view (we will also update the root/path)\n",
    "new_path = '/ourdisk/hpc/ai2es'\n",
    "data_train1 = create_imagefolder(dict, samples_train1, dummy_path, trans, new_path)\n",
    "data_unlbl1 = create_imagefolder(dict, samples_unlbl1, dummy_path, trans, new_path)\n",
    "data_val1 = create_imagefolder(dict, samples_val1, dummy_path, trans, new_path)\n",
    "data_test1 = create_imagefolder(dict, samples_test1, dummy_path, trans, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 754\n",
      "    Root location: /ourdisk/hpc/ai2es/jroth/data/labeled\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               CenterCrop(size=(224, 224))\n",
      "               ToTensor()\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 754\n",
      "    Root location: /ourdisk/hpc/ai2es\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               CenterCrop(size=(224, 224))\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(data_train0)\n",
    "print(data_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# testing the dataset updates so that they work correctly (samples added and removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_imagefolder(paths, labels, dataset):\n",
    "    \"\"\"\n",
    "    Adds the paths with the labels to an image classification dataset\n",
    "\n",
    "    :list paths: a list of absolute image paths to add to the dataset\n",
    "    :list labels: a list of labels for each path\n",
    "    :Dataset dataset: the dataset to add the samples to\n",
    "    \"\"\"\n",
    "\n",
    "    new_samples = list(zip(paths, labels))\n",
    "\n",
    "    dataset.samples += new_samples\n",
    "\n",
    "    return dataset.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "TJV3jF3VfqVu"
   },
   "outputs": [],
   "source": [
    "def predict(loader, model, device):\n",
    "    print(f\"Number of instances to predict: {len(loader.dataset)}\")\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X)\n",
    "            predictions.append(output)\n",
    "    return torch.cat(predictions) # output shape (# instances, # outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cotrain(loader0, loader1, loader_unlbl0, loader_unlbl1,\n",
    "            model0, model1, k, device):\n",
    "    pred_model0 = predict(loader_unlbl0, model0, device)\n",
    "    pred_model1 = predict(loader_unlbl1, model1, device)\n",
    "\n",
    "    _, lbl_topk0, idx_topk0 = get_topk_predictions(\n",
    "                                    pred_model0,\n",
    "                                    k if k <= len(pred_model0) else len(pred_model0))\n",
    "    _, lbl_topk1, idx_topk1 = get_topk_predictions(\n",
    "                                    pred_model1, \n",
    "                                    k if k <= len(pred_model1) else len(pred_model1))\n",
    "\n",
    "    print(f\"Number of unlabeled instances: {len(loader_unlbl0.dataset)}\")\n",
    "\n",
    "    # if two models predict confidently on the same instance,\n",
    "    # find and remove conflicting predictions from the lists\n",
    "    lbl_topk0, idx_topk0, lbl_topk1, idx_topk1, lbl_colls, idx_colls = \\\n",
    "    remove_collisions(lbl_topk0, idx_topk0, lbl_topk1, idx_topk1)\n",
    "\n",
    "    print(\"\\nLast 3 elements of top-k:\\n lbl0: {}\\t lbl1: {}\\t idx0: {}\\t idx1: {}\"\n",
    "          .format(lbl_topk0[-3:], lbl_topk1[-3:],\n",
    "                 idx_topk0[-3:], idx_topk1[-3:]))\n",
    "\n",
    "    samples_unlbl0 = np.stack([np.array(a) for a in loader_unlbl0.dataset.samples])\n",
    "    samples_unlbl1 = np.stack([np.array(a) for a in loader_unlbl1.dataset.samples])\n",
    "\n",
    "    if len(idx_colls) > 0:\n",
    "        print(\"\\nImage paths, labels of collisions:\\n unlbl0: {}\\n unlbl1: {}\\n labels: {}\"\n",
    "             .format(samples_unlbl0[idx_colls],\n",
    "                     samples_unlbl1[idx_colls], \n",
    "                     lbl_colls))\n",
    "\n",
    "    # retrieve the instances that have been labeled with high confidence by the other model\n",
    "    list_samples0 = [(str(a[0]), int(a[1])) for a in list(samples_unlbl0[idx_topk1])]\n",
    "    list_samples1 = [(str(a[0]), int(a[1])) for a in list(samples_unlbl1[idx_topk0])]\n",
    "\n",
    "    print(\"\\nLast 3 instances:\\n samples0:\\n {} \\n samples1:\\n {}\"\n",
    "          .format(list_samples0[-3:], list_samples1[-3:]))\n",
    "\n",
    "    # image paths for both\n",
    "    paths0 = [i for i, _ in list_samples0]\n",
    "    paths1 = [i for i, _ in list_samples1]\n",
    "\n",
    "    # add pseudolabeled instances to the labeled datasets\n",
    "    loader0.dataset.samples = add_to_imagefolder(paths0, lbl_topk1.tolist(), loader0.dataset)\n",
    "    loader1.dataset.samples = add_to_imagefolder(paths1, lbl_topk0.tolist(), loader1.dataset)\n",
    "\n",
    "    print(\"\\nLast 3 instances:\\n loader0:\\n {} \\n loader1:\\n {}\"\n",
    "          .format(loader0.dataset.samples[-3:],\n",
    "                  loader1.dataset.samples[-3:]))\n",
    "\n",
    "    # remove instances from unlabeled dataset\n",
    "    mask = np.ones(len(loader_unlbl0.dataset), dtype=bool)\n",
    "    mask[idx_topk0] = False\n",
    "    mask[idx_topk1] = False\n",
    "\n",
    "    print(f\"Number of unlabeled instances to remove: {(~mask).sum()}\")\n",
    "\n",
    "    samples_unlbl0 = samples_unlbl0[mask]\n",
    "    samples_unlbl1 = samples_unlbl1[mask]\n",
    "\n",
    "    list_unlbl0 = [(str(a[0]), int(a[1])) for a in list(samples_unlbl0)]\n",
    "    list_unlbl1 = [(str(a[0]), int(a[1])) for a in list(samples_unlbl1)]\n",
    "\n",
    "    loader_unlbl0.dataset.samples = list_unlbl0\n",
    "    loader_unlbl1.dataset.samples = list_unlbl1\n",
    "\n",
    "    print(f\"Remaining number of unlabeled instances: {len(loader_unlbl0.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_kwargs = {'batch_size': 64, 'shuffle': False}\n",
    "\n",
    "loader_train0 = DataLoader(data_train0, **loader_kwargs)\n",
    "loader_unlbl0 = DataLoader(data_unlbl0, **loader_kwargs)\n",
    "loader_val0 = DataLoader(data_val0, **loader_kwargs)\n",
    "loader_test0 = DataLoader(data_test0, **loader_kwargs)\n",
    "\n",
    "loader_train1 = DataLoader(data_train1, **loader_kwargs)\n",
    "loader_unlbl1 = DataLoader(data_unlbl1, **loader_kwargs)\n",
    "loader_val1 = DataLoader(data_val1, **loader_kwargs)\n",
    "loader_test1 = DataLoader(data_test1, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copies to verify that things are getting removed as they should\n",
    "train0_copy = copy.deepcopy(data_train0)\n",
    "unlbl0_copy = copy.deepcopy(data_unlbl0)\n",
    "\n",
    "train1_copy = copy.deepcopy(data_train1)\n",
    "unlbl1_copy = copy.deepcopy(data_unlbl1)\n",
    "\n",
    "train0_copy_np = np.stack([np.array(a) for a in train0_copy.samples])\n",
    "unlbl0_copy_np = np.stack([np.array(a) for a in unlbl0_copy.samples])\n",
    "\n",
    "train1_copy_np = np.stack([np.array(a) for a in train1_copy.samples])\n",
    "unlbl1_copy_np = np.stack([np.array(a) for a in unlbl1_copy.samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = resnet50(num_classes=3).to(device)\n",
    "\n",
    "# re-set the seed so we get a different set of weights\n",
    "torch.manual_seed(1729)\n",
    "model1 = resnet50(num_classes=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 32\n",
      "Number of instances to predict: 3227\n",
      "Number of instances to predict: 3227\n",
      "Number of unlabeled instances: 3227\n",
      "Intersection: [] \n",
      "idx_inter0: [] \n",
      "idx_inter1: []\n",
      "\n",
      "Last 3 elements of top-k:\n",
      " lbl0: [2 2 2]\t lbl1: [1 1 1]\t idx0: [2866 1108  263]\t idx1: [464 472 477]\n",
      "\n",
      "Last 3 instances:\n",
      " samples0:\n",
      " [('/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-01-26-05-01-16.jpg', 0), ('/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-01-26-11-31-06.jpg', 0), ('/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-02-15-23-00-47.jpg', 0)] \n",
      " samples1:\n",
      " [('/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220222/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-22-22:55:27.jpg', 2), ('/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220203/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-03-23:45:28.jpg', 2), ('/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220206/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-06-00:00:14.jpg', 0)]\n",
      "\n",
      "Last 3 instances:\n",
      " loader0:\n",
      " [('/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-01-26-05-01-16.jpg', 1), ('/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-01-26-11-31-06.jpg', 1), ('/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-02-15-23-00-47.jpg', 1)] \n",
      " loader1:\n",
      " [('/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220222/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-22-22:55:27.jpg', 2), ('/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220203/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-03-23:45:28.jpg', 2), ('/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220206/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-06-00:00:14.jpg', 2)]\n",
      "Number of unlabeled instances to remove: 64\n",
      "Remaining number of unlabeled instances: 3163\n"
     ]
    }
   ],
   "source": [
    "k = int(len(loader_unlbl0.dataset) * 0.01)\n",
    "print(f\"k: {k}\")\n",
    "\n",
    "cotrain(loader_train0, loader_train1, loader_unlbl0, loader_unlbl1, model0, model1, k, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instances in original, updated unlabeled set (view 0):\n",
      "[['/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-01-26-05-01-16.jpg'\n",
      "  '0']\n",
      " ['/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-01-26-11-31-06.jpg'\n",
      "  '0']\n",
      " ['/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-02-15-23-00-47.jpg'\n",
      "  '0']]\n",
      "[['/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/wet/NYSDOT_m4er5dez4ab_2022-02-04-04-46-10.jpg'\n",
      "  '2']\n",
      " ['/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/snow/NYSDOT_m4er5dez4ab_2022-01-29-09-35-57.jpg'\n",
      "  '1']\n",
      " ['/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_uyomtjhwsay_2022-02-21-18-00-46.jpg'\n",
      "  '0']]\n",
      "\n",
      "instances in original, updated unlabeled set (view 1):\n",
      "[['/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220222/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-22-22:55:27.jpg'\n",
      "  '2']\n",
      " ['/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220203/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-03-23:45:28.jpg'\n",
      "  '2']\n",
      " ['/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220206/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-06-00:00:14.jpg'\n",
      "  '0']]\n",
      "[['/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220315/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-03-15-13:00:28.jpg'\n",
      "  '0']\n",
      " ['/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220201/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-01-03:00:20.jpg'\n",
      "  '0']\n",
      " ['/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220213/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-13-09:30:24.jpg'\n",
      "  '2']]\n",
      "\n",
      "last 3 instances in original train set:\n",
      "['/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-02-20-13-00-53.jpg'\n",
      " '/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/wet/NYSDOT_m4er5dez4ab_2022-02-07-16-21-05.jpg'\n",
      " '/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_uyomtjhwsay_2022-02-09-23-30-52.jpg']\n",
      "['/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220220/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-20-13:00:25.jpg'\n",
      " '/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220207/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-07-16:20:19.jpg'\n",
      " '/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220209/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-09-23:30:15.jpg']\n",
      "\n",
      "last 3 instances in updated train set:\n",
      "[['/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-01-26-05-01-16.jpg'\n",
      "  '1']\n",
      " ['/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-01-26-11-31-06.jpg'\n",
      "  '1']\n",
      " ['/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-02-15-23-00-47.jpg'\n",
      "  '1']]\n",
      "[['/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220222/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-22-22:55:27.jpg'\n",
      "  '2']\n",
      " ['/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220203/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-03-23:45:28.jpg'\n",
      "  '2']\n",
      " ['/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220206/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-06-00:00:14.jpg'\n",
      "  '2']]\n",
      "\n",
      "3 elements from top-k predictions:\n",
      "['/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-01-26-05-01-16.jpg'\n",
      " '/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-01-26-11-31-06.jpg'\n",
      " '/ourdisk/hpc/ai2es/jroth/data/labeled/bronx_allsites/dry/NYSDOT_m4er5dez4ab_2022-02-15-23-00-47.jpg']\n",
      "['/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220222/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-22-22:55:27.jpg'\n",
      " '/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220203/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-03-23:45:28.jpg'\n",
      " '/ourdisk/hpc/ai2es/datasets/DOT/Skyline_6464/20220206/I_87_at_Interchange_3_(Yonkers_Mile_Square_Road)__Northbound__Skyline_6464_2022-02-06-00:00:14.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Some checks to see if the images are still aligned\n",
    "# and the datasets are updated correctly (...)\n",
    "\n",
    "print(\"instances in original, updated unlabeled set (view 0):\")\n",
    "temp_unlbl0 = np.stack([np.array(a) for a in loader_unlbl0.dataset.samples])\n",
    "print(unlbl0_copy_np[[[64, 472, 477]])\n",
    "print(temp_unlbl0[[464, 472, 477]])\n",
    "\n",
    "print(\"\\ninstances in original, updated unlabeled set (view 1):\")\n",
    "temp_unlbl1 = np.stack([np.array(a) for a in loader_unlbl1.dataset.samples])\n",
    "print(unlbl1_copy_np[[2866, 1108, 263]])\n",
    "print(temp_unlbl1[[2866, 1108, 263]])\n",
    "\n",
    "print(\"\\nlast 3 instances in original train set:\")\n",
    "print(train0_copy_np[-3:][:,0])\n",
    "print(train1_copy_np[-3:][:,0])\n",
    "\n",
    "print(\"\\nlast 3 instances in updated train set:\")\n",
    "temp_train0 = np.stack([np.array(a) for a in loader_train0.dataset.samples])\n",
    "temp_train1 = np.stack([np.array(a) for a in loader_train1.dataset.samples])\n",
    "print(temp_train0[-3:])\n",
    "print(temp_train1[-3:])\n",
    "\n",
    "print(\"\\n3 elements from top-k predictions:\")\n",
    "print(unlbl0_copy_np[[464, 472, 477]][:,0])\n",
    "print(unlbl1_copy_np[[2866, 1108, 263]][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(loader, model, loss_fn, optimizer, device):\n",
    "#     size = len(loader.dataset)\n",
    "#     model.train()\n",
    "#     for batch, (X, y) in enumerate(loader):\n",
    "#         X, y = X.to(device), y.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         # Compute prediction error\n",
    "#         pred = model(X)\n",
    "#         loss = loss_fn(pred, y)\n",
    "\n",
    "#         # Backpropagation\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         loss, current = loss, (batch + 1) * len(X)\n",
    "#         print(f\"loss: {loss:>7f} [{current:5d} / {size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(loader, model, loss_fn, device):\n",
    "#   size = len(loader.dataset)\n",
    "#   num_batches = len(loader)\n",
    "#   model.eval()\n",
    "#   test_loss, correct = 0, 0\n",
    "#   with torch.no_grad():\n",
    "#     for X, y in loader:\n",
    "#       X, y = X.to(device), y.to(device)\n",
    "#       pred = model(X)\n",
    "#       test_loss += loss_fn(pred, y).item()\n",
    "#       correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "#     test_loss /= num_batches\n",
    "#     correct /= size\n",
    "      \n",
    "#     print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "#     return correct, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define loss function and optimizer\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer0 = torch.optim.SGD(model0.parameters(), lr=1e-3,momentum=0.9)\n",
    "# optimizer1 = torch.optim.SGD(model1.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "# # we also need to define some sort of learning rate/early stopping scheduler\n",
    "# scheduler0 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer0)\n",
    "# scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # re-update the train, unlabeled datasets as those were modified previously\n",
    "# loader_train0 = DataLoader(train0_copy, **loader_kwargs)\n",
    "# loader_unlbl0 = DataLoader(unlbl0_copy, **loader_kwargs)\n",
    "\n",
    "# loader_train1 = DataLoader(train1_copy, **loader_kwargs)\n",
    "# loader_unlbl1 = DataLoader(unlbl1_copy, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(loader_train0.dataset))\n",
    "# print(len(loader_unlbl0.dataset))\n",
    "\n",
    "# print(len(loader_train1.dataset))\n",
    "# print(len(loader_unlbl1.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterations = 1\n",
    "# epochs = 3\n",
    "# k = int(len(loader_unlbl0.dataset) * 0.05)\n",
    "# print(f\"k: {k}\")\n",
    "\n",
    "# for i in range(iterations):\n",
    "#     print(f\"Co-training iteration {i + 1}\")\n",
    "#     print(\"training model0...\")\n",
    "#     for epoch in range(epochs):\n",
    "#         print(f\"Epoch {epoch + 1} \\n-------------------------------------------\")\n",
    "#         train(loader_train0, model0, loss_fn, optimizer0, device)\n",
    "#         val_acc0, val_loss0 = test(loader_val0, model0, loss_fn, device)\n",
    "#         # NOTE should have an early stopping check here\n",
    "#         scheduler0.step(val_loss0)\n",
    "\n",
    "#     print(\"training model1...\")\n",
    "#     for epoch in range(epochs):\n",
    "#         print(f\"Epoch {epoch + 1} \\n-------------------------------------------\")\n",
    "#         train(loader_train1, model1, loss_fn, optimizer1, device)\n",
    "#         val_acc1, val_loss1 = test(loader_val1, model1, loss_fn, device)\n",
    "#         # NOTE should have an early stopping check here\n",
    "#         scheduler0.step(val_loss1)\n",
    "\n",
    "#     cotrain(loader_train0, loader_train1, loader_unlbl0, loader_unlbl1, model0, model1, k, device)\n",
    "#     test_acc0, test_loss0 = test(loader_test0, model0, loss_fn, device)\n",
    "#     test_acc1, test_loss1 = test(loader_test1, model1, loss_fn, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
